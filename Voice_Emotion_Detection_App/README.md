# ğŸ™ï¸ Voice Emotion Detection App

![Python](https://img.shields.io/badge/Language-Python-blue)
![Streamlit](https://img.shields.io/badge/Framework-Streamlit-red)
![Machine Learning](https://img.shields.io/badge/Domain-Machine%20Learning-brightgreen)
![Status](https://img.shields.io/badge/Status-Completed-success)

A **Machine Learningâ€“based Voice Emotion Detection System** that analyzes human speech and predicts emotional states such as **Happy, Sad, Angry, Fear, Calm, and Neutral** using audio features and trained ML models.

---

## ğŸš€ Project Overview

Human voice carries rich emotional information. This project focuses on extracting meaningful audio features from speech signals and using them to classify emotions accurately.

The application is deployed using **Streamlit**, providing a clean and interactive web interface where users can upload voice samples and instantly see emotion predictions.

---

## ğŸ§  Emotions Detected

* ğŸ˜Š Happy
* ğŸ˜¢ Sad
* ğŸ˜  Angry
* ğŸ˜¨ Fear
* ğŸ˜Œ Calm
* ğŸ˜ Neutral

---

## ğŸ› ï¸ Tech Stack

| Category             | Technology                   |
| -------------------- | ---------------------------- |
| Programming Language | Python                       |
| ML Libraries         | NumPy, Pandas, Scikit-learn  |
| Audio Processing     | Librosa                      |
| Model Type           | Classical ML / Feature-based |
| Web Framework        | Streamlit                    |
| Version Control      | Git & GitHub                 |

---

## âš™ï¸ Features

* ğŸ§ Upload `.wav` audio files
* ğŸ” Audio feature extraction (MFCC, Chroma, Mel Spectrogram)
* ğŸ¤– Emotion prediction using trained ML model
* ğŸ“Š Clean & interactive Streamlit UI
* ğŸ§ª Modular project structure (Core + App)

---

## ğŸ“ Project Structure

```
voice_emotion_detection_app/
â”‚
â”œâ”€â”€ Voice_Emotion_Detection_App/
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â””â”€â”€ assets/
â”‚
â”œâ”€â”€ Voice_Emotion_Detection_Core/
â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ img.jpg
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/kanha165/voice_emotion_detection_app.git
cd voice_emotion_detection_app
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate   # Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run Streamlit App

```bash
streamlit run Voice_Emotion_Detection_App/streamlit_app.py
```

---

## ğŸ“¸ Screenshots

> Add screenshots of your Streamlit UI here

```
/screenshot1.png
/screenshot2.png
```

---

## ğŸ¯ Use Cases

* ğŸ¤ Humanâ€“Computer Interaction
* ğŸ§  Mental Health Analysis
* ğŸ“ Call Center Emotion Analytics
* ğŸ® Gaming & Virtual Assistants

---

## ğŸ”® Future Enhancements

* ğŸ¯ Deep Learning (CNN / LSTM)
* ğŸ“± Mobile App Integration
* ğŸŒ Multilingual Emotion Detection
* ğŸ™ï¸ Real-time microphone input

---

## ğŸ‘¨â€ğŸ’» Author

**Kanha Patidar**
B.Tech â€“ Computer Science (IT)
ğŸ“ Indore, India

* GitHub: [https://github.com/kanha165](https://github.com/kanha165)
* LinkedIn: (Add your LinkedIn profile link)

---

## â­ Support

If you found this project helpful:

* â­ Star this repository
* ğŸ´ Fork it
* ğŸ§  Share feedback

---

ğŸ”¥ *Built with passion for Machine Learning & AI*
# Voice Emotion Detection Project
